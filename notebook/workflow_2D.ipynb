{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Cell Analysis\n",
    "\n",
    "Interactive notebook for analyzing place cells in 2D environment navigation. Equivalent to:\n",
    "```bash\n",
    "pdm run pcell workflow visualize --config placecell/config/example_pcell_config.yaml --data user_data/WL25_20251201/WL25_20251201.yaml\n",
    "```\n",
    "\n",
    "This notebook runs the full workflow:\n",
    "1. **Deconvolution** - Extract neural events using OASIS\n",
    "2. **Event-Place Matching** - Match events to behavior positions\n",
    "3. **Interactive Visualization** - Browse place cells with scrollable interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from placecell.config import AppConfig, DataPathsConfig\n",
    "from placecell.io import load_behavior_data, load_neural_data\n",
    "from placecell.analysis import (\n",
    "    compute_occupancy_map, \n",
    "    compute_unit_analysis,\n",
    "    build_event_place_dataframe,\n",
    "    load_traces,\n",
    "    load_curated_unit_ids,\n",
    ")\n",
    "from placecell.visualization import plot_summary_scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - adjust these as needed\n",
    "CONFIG_PATH = project_root / \"placecell/config/example_pcell_config.yaml\"\n",
    "DATA_PATH = project_root / \"user_data/WL25_20251201/WL25_20251201.yaml\"\n",
    "DATA_DIR = DATA_PATH.parent\n",
    "OUTPUT_DIR = project_root / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configs\n",
    "cfg = AppConfig.from_yaml(CONFIG_PATH)\n",
    "data_cfg = DataPathsConfig.from_yaml(DATA_PATH)\n",
    "\n",
    "# Resolve data paths relative to data directory\n",
    "neural_path = DATA_DIR / data_cfg.neural_path\n",
    "neural_timestamp = DATA_DIR / data_cfg.neural_timestamp\n",
    "behavior_position = DATA_DIR / data_cfg.behavior_position\n",
    "behavior_timestamp = DATA_DIR / data_cfg.behavior_timestamp\n",
    "curation_csv = (DATA_DIR / data_cfg.curation_csv) if data_cfg.curation_csv else None\n",
    "\n",
    "print(f\"Config: {CONFIG_PATH}\")\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Neural path: {neural_path}\")\n",
    "print(f\"Neural timestamp: {neural_timestamp}\")\n",
    "print(f\"Behavior position: {behavior_position}\")\n",
    "print(f\"Behavior timestamp: {behavior_timestamp}\")\n",
    "print(f\"Curation CSV: {curation_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract config values\n",
    "bodypart = cfg.behavior.bodypart\n",
    "behavior_fps = cfg.behavior.behavior_fps\n",
    "speed_threshold = cfg.behavior.speed_threshold\n",
    "speed_window_frames = cfg.behavior.speed_window_frames\n",
    "bins = cfg.behavior.spatial_map.bins\n",
    "min_occupancy = cfg.behavior.spatial_map.min_occupancy\n",
    "occupancy_sigma = cfg.behavior.spatial_map.occupancy_sigma\n",
    "activity_sigma = cfg.behavior.spatial_map.activity_sigma\n",
    "n_shuffles = cfg.behavior.spatial_map.n_shuffles\n",
    "random_seed = cfg.behavior.spatial_map.random_seed\n",
    "event_threshold_sigma = cfg.behavior.spatial_map.event_threshold_sigma\n",
    "p_value_threshold = cfg.behavior.spatial_map.p_value_threshold\n",
    "stability_threshold = cfg.behavior.spatial_map.stability_threshold\n",
    "\n",
    "# Neural config\n",
    "trace_name = cfg.neural.trace_name\n",
    "neural_fps = cfg.neural.fps\n",
    "max_units = cfg.neural.max_units\n",
    "g = cfg.neural.oasis.g\n",
    "baseline = cfg.neural.oasis.baseline\n",
    "penalty = cfg.neural.oasis.penalty\n",
    "s_min = cfg.neural.oasis.s_min\n",
    "\n",
    "# Visualization settings\n",
    "trace_time_window = 600.0  # 10 minutes window for trace display\n",
    "\n",
    "print(f\"Bodypart: {bodypart}\")\n",
    "print(f\"Speed threshold: {speed_threshold} px/s\")\n",
    "print(f\"Bins: {bins}\")\n",
    "print(f\"Shuffles: {n_shuffles}\")\n",
    "print(f\"Trace name: {trace_name}\")\n",
    "print(f\"OASIS g: {g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deconvolution\n",
    "\n",
    "Run OASIS deconvolution to extract neural events from calcium traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oasis.oasis_methods import oasisAR2\n",
    "\n",
    "# Load traces\n",
    "print(f\"Loading traces from: {neural_path / (trace_name + '.zarr')}\")\n",
    "C_da = load_traces(neural_path, trace_name=trace_name)\n",
    "all_unit_ids = list(map(int, C_da[\"unit_id\"].values))\n",
    "print(f\"Total units in traces: {len(all_unit_ids)}\")\n",
    "\n",
    "# Filter by curation CSV if provided\n",
    "if curation_csv is not None and curation_csv.exists():\n",
    "    curated_ids = set(load_curated_unit_ids(curation_csv))\n",
    "    all_unit_ids = [uid for uid in all_unit_ids if uid in curated_ids]\n",
    "    print(f\"After curation filter: {len(all_unit_ids)} units\")\n",
    "\n",
    "# Apply max_units limit if configured\n",
    "if max_units is not None and len(all_unit_ids) > max_units:\n",
    "    all_unit_ids = all_unit_ids[:max_units]\n",
    "    print(f\"Limited to first {max_units} units\")\n",
    "\n",
    "print(f\"Will process {len(all_unit_ids)} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OASIS deconvolution\n",
    "print(f\"Running OASIS deconvolution (g={g})...\")\n",
    "\n",
    "good_unit_ids = []\n",
    "C_list = []\n",
    "S_list = []\n",
    "\n",
    "for uid in tqdm(all_unit_ids, desc=\"Deconvolving units\"):\n",
    "    y = np.ascontiguousarray(C_da.sel(unit_id=uid).values, dtype=np.float64)\n",
    "    \n",
    "    # Baseline correction\n",
    "    if isinstance(baseline, str) and baseline.startswith(\"p\"):\n",
    "        p = float(baseline[1:])\n",
    "        b = float(np.percentile(y, p))\n",
    "    else:\n",
    "        b = float(baseline)\n",
    "    \n",
    "    y_corrected = y - b\n",
    "    \n",
    "    try:\n",
    "        c, s = oasisAR2(y_corrected, g1=g[0], g2=g[1], lam=penalty, s_min=s_min)\n",
    "        good_unit_ids.append(int(uid))\n",
    "        C_list.append(np.asarray(c, dtype=float))\n",
    "        S_list.append(np.asarray(s, dtype=float))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping unit {uid}: {e}\")\n",
    "\n",
    "print(f\"Successfully deconvolved {len(good_unit_ids)} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build event index DataFrame\n",
    "event_rows = []\n",
    "S_arr = np.stack(S_list, axis=0)\n",
    "\n",
    "for i, uid in enumerate(good_unit_ids):\n",
    "    s_vec = S_arr[i]\n",
    "    frames = np.nonzero(s_vec > 0)[0]\n",
    "    for fr in frames:\n",
    "        event_rows.append({\"unit_id\": uid, \"frame\": int(fr), \"s\": float(s_vec[fr])})\n",
    "\n",
    "event_index_df = pd.DataFrame(event_rows)\n",
    "print(f\"Total events detected: {len(event_index_df)}\")\n",
    "\n",
    "# Save event index (optional)\n",
    "event_index_csv = OUTPUT_DIR / \"event_index_notebook.csv\"\n",
    "event_index_df.to_csv(event_index_csv, index=False)\n",
    "print(f\"Saved event index to: {event_index_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Event-Place Matching\n",
    "\n",
    "Match neural events to behavior positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build event-place dataframe\n",
    "print(\"Matching events to behavior positions...\")\n",
    "\n",
    "event_place_df = build_event_place_dataframe(\n",
    "    event_index_path=event_index_csv,\n",
    "    neural_timestamp_path=neural_timestamp,\n",
    "    behavior_position_path=behavior_position,\n",
    "    behavior_timestamp_path=behavior_timestamp,\n",
    "    bodypart=bodypart,\n",
    "    behavior_fps=behavior_fps,\n",
    "    speed_threshold=speed_threshold,\n",
    "    speed_window_frames=speed_window_frames,\n",
    ")\n",
    "\n",
    "print(f\"Event-place entries: {len(event_place_df)}\")\n",
    "print(f\"Unique units: {event_place_df['unit_id'].nunique()}\")\n",
    "\n",
    "# Save event-place (optional)\n",
    "event_place_csv = OUTPUT_DIR / \"event_place_notebook.csv\"\n",
    "event_place_df.to_csv(event_place_csv, index=False)\n",
    "print(f\"Saved event-place to: {event_place_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by speed threshold\n",
    "df_filtered = event_place_df[event_place_df[\"speed\"] > speed_threshold].copy()\n",
    "df_all_events = event_index_df.copy()\n",
    "\n",
    "print(f\"Speed-filtered events: {len(df_filtered)}\")\n",
    "print(f\"Unique units after filtering: {df_filtered['unit_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavior data\n",
    "trajectory_with_speed, trajectory_df = load_behavior_data(\n",
    "    behavior_position=behavior_position,\n",
    "    behavior_timestamp=behavior_timestamp,\n",
    "    bodypart=bodypart,\n",
    "    speed_window_frames=speed_window_frames,\n",
    "    speed_threshold=speed_threshold,\n",
    ")\n",
    "\n",
    "print(f\"Trajectory frames: {len(trajectory_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute occupancy map\n",
    "occupancy_time, valid_mask, x_edges, y_edges = compute_occupancy_map(\n",
    "    trajectory_df=trajectory_df,\n",
    "    bins=bins,\n",
    "    behavior_fps=behavior_fps,\n",
    "    occupancy_sigma=occupancy_sigma,\n",
    "    min_occupancy=min_occupancy,\n",
    ")\n",
    "\n",
    "print(f\"Occupancy map shape: {occupancy_time.shape}\")\n",
    "print(f\"Valid bins: {valid_mask.sum()} / {valid_mask.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neural data (for visualization)\n",
    "traces, max_proj, footprints = load_neural_data(\n",
    "    neural_path=neural_path,\n",
    "    trace_name=trace_name,\n",
    ")\n",
    "\n",
    "print(f\"Traces shape: {traces.shape if traces is not None else 'None'}\")\n",
    "print(f\"Max proj shape: {max_proj.shape if max_proj is not None else 'None'}\")\n",
    "print(f\"Footprints shape: {footprints.shape if footprints is not None else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute Unit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "if random_seed is not None:\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "# Compute analysis for each unit\n",
    "unique_units = sorted(df_filtered[\"unit_id\"].unique())\n",
    "n_units = len(unique_units)\n",
    "print(f\"Computing analysis for {n_units} units...\")\n",
    "\n",
    "unit_results = {}\n",
    "for unit_id in tqdm(unique_units, desc=\"Computing unit analysis\"):\n",
    "    result = compute_unit_analysis(\n",
    "        unit_id=unit_id,\n",
    "        df_filtered=df_filtered,\n",
    "        trajectory_df=trajectory_df,\n",
    "        occupancy_time=occupancy_time,\n",
    "        valid_mask=valid_mask,\n",
    "        x_edges=x_edges,\n",
    "        y_edges=y_edges,\n",
    "        activity_sigma=activity_sigma,\n",
    "        event_threshold_sigma=event_threshold_sigma,\n",
    "        n_shuffles=n_shuffles,\n",
    "        behavior_fps=behavior_fps,\n",
    "        min_occupancy=min_occupancy,\n",
    "        stability_threshold=stability_threshold,\n",
    "    )\n",
    "\n",
    "    # Visualization data\n",
    "    vis_data_above = result[\"events_above_threshold\"]\n",
    "    vis_data_below = pd.DataFrame()\n",
    "    if df_all_events is not None:\n",
    "        unit_all_events = df_all_events[df_all_events[\"unit_id\"] == unit_id]\n",
    "        vis_data_below = unit_all_events[unit_all_events[\"s\"] > result[\"vis_threshold\"]]\n",
    "\n",
    "    # Trace data\n",
    "    trace_data = None\n",
    "    trace_times = None\n",
    "    if traces is not None:\n",
    "        try:\n",
    "            trace_data = traces.sel(unit_id=int(unit_id)).values\n",
    "            trace_times = np.arange(len(trace_data)) / neural_fps\n",
    "        except (KeyError, IndexError):\n",
    "            pass\n",
    "\n",
    "    unit_results[unit_id] = {\n",
    "        \"rate_map\": result[\"rate_map\"],\n",
    "        \"si\": result[\"si\"],\n",
    "        \"shuffled_sis\": result[\"shuffled_sis\"],\n",
    "        \"p_val\": result[\"p_val\"],\n",
    "        \"stability_corr\": result[\"stability_corr\"],\n",
    "        \"stability_z\": result[\"stability_z\"],\n",
    "        \"vis_data_above\": vis_data_above,\n",
    "        \"vis_data_below\": vis_data_below,\n",
    "        \"unit_data\": result[\"unit_data\"],\n",
    "        \"trace_data\": trace_data,\n",
    "        \"trace_times\": trace_times,\n",
    "    }\n",
    "\n",
    "print(f\"Done. Computed analysis for {len(unit_results)} units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_occ, axes_occ = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Trajectory\n",
    "axes_occ[0].plot(trajectory_df[\"x\"], trajectory_df[\"y\"], \"k-\", alpha=0.5, linewidth=0.5)\n",
    "axes_occ[0].set_title(\"Trajectory (speed-filtered)\")\n",
    "axes_occ[0].set_aspect(\"equal\")\n",
    "axes_occ[0].axis(\"off\")\n",
    "\n",
    "# Occupancy map\n",
    "im = axes_occ[1].imshow(\n",
    "    occupancy_time.T, origin=\"lower\", cmap=\"hot\", aspect=\"equal\",\n",
    "    extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]]\n",
    ")\n",
    "axes_occ[1].contour(valid_mask.T, levels=[0.5], colors=\"white\", linewidths=1.5,\n",
    "                    extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "axes_occ[1].set_title(f\"Occupancy (sigma={occupancy_sigma}, min={min_occupancy}s)\")\n",
    "plt.colorbar(im, ax=axes_occ[1], label=\"Time (s)\")\n",
    "\n",
    "# Speed distribution\n",
    "all_speeds = trajectory_with_speed[\"speed\"].values\n",
    "speed_max = np.percentile(all_speeds[~np.isnan(all_speeds)], 99)\n",
    "axes_occ[2].hist(all_speeds.clip(max=speed_max), bins=50, color=\"gray\", alpha=0.7)\n",
    "axes_occ[2].axvline(speed_threshold, color=\"red\", linestyle=\"--\", linewidth=2,\n",
    "                    label=f\"Threshold={speed_threshold}\")\n",
    "axes_occ[2].set_title(\"Speed distribution\")\n",
    "axes_occ[2].set_xlabel(\"Speed (px/s)\")\n",
    "axes_occ[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = plot_summary_scatter(\n",
    "    unit_results,\n",
    "    p_value_threshold=p_value_threshold,\n",
    "    stability_threshold=stability_threshold,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Cell Browser\n",
    "\n",
    "Use the slider to scroll through cells. Use the time slider to scroll through the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive browser with ipympl (requires: pdm install -G notebook)\n",
    "%matplotlib widget\n",
    "\n",
    "# Create figure once\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Create axes\n",
    "ax1 = fig.add_axes([0.03, 0.42, 0.18, 0.45])  # Max projection\n",
    "ax2 = fig.add_axes([0.25, 0.42, 0.18, 0.45])  # Trajectory\n",
    "ax3 = fig.add_axes([0.47, 0.42, 0.16, 0.45])  # Rate map\n",
    "ax3_cbar = fig.add_axes([0.635, 0.49, 0.015, 0.315])  # Colorbar\n",
    "ax4 = fig.add_axes([0.74, 0.42, 0.18, 0.45])  # SI histogram\n",
    "ax5 = fig.add_axes([0.05, 0.08, 0.90, 0.28])  # Trace\n",
    "\n",
    "# Text annotations holder\n",
    "text_annotations = []\n",
    "\n",
    "def render_unit(unit_idx, trace_start):\n",
    "    \"\"\"Render visualization for a specific unit (in-place update).\"\"\"\n",
    "    global text_annotations\n",
    "    \n",
    "    unit_id = unique_units[unit_idx]\n",
    "    result = unit_results[unit_id]\n",
    "    \n",
    "    # Clear all axes\n",
    "    for ax in [ax1, ax2, ax3, ax3_cbar, ax4, ax5]:\n",
    "        ax.clear()\n",
    "    \n",
    "    # Clear text annotations\n",
    "    for txt in text_annotations:\n",
    "        txt.remove()\n",
    "    text_annotations = []\n",
    "    \n",
    "    # 1. Max projection with neuron footprint\n",
    "    if max_proj is not None:\n",
    "        ax1.imshow(max_proj, cmap=\"gray\", aspect=\"equal\")\n",
    "        if footprints is not None:\n",
    "            try:\n",
    "                unit_fp = footprints.sel(unit_id=unit_id).values\n",
    "                if unit_fp.max() > 0:\n",
    "                    ax1.contour(unit_fp, levels=[unit_fp.max() * 0.3], \n",
    "                               colors=\"red\", linewidths=1.5)\n",
    "            except (KeyError, IndexError, ValueError):\n",
    "                pass\n",
    "        ax1.set_title(f\"Unit {unit_id}\")\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, \"No max projection\", ha=\"center\", va=\"center\", \n",
    "                transform=ax1.transAxes)\n",
    "        ax1.set_title(f\"Unit {unit_id}\")\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    # 2. Trajectory + events\n",
    "    vis_data_above = result[\"vis_data_above\"]\n",
    "    ax2.plot(trajectory_df[\"x\"], trajectory_df[\"y\"], \"k-\", alpha=1.0, \n",
    "            linewidth=1, zorder=1)\n",
    "    \n",
    "    if not vis_data_above.empty:\n",
    "        amps = vis_data_above[\"s\"].values\n",
    "        amp_max = np.max(amps) if len(amps) > 0 and np.max(amps) > 0 else 1.0\n",
    "        alphas = amps / amp_max\n",
    "        ax2.scatter(vis_data_above[\"x\"], vis_data_above[\"y\"], c=\"red\", \n",
    "                   s=30, alpha=alphas, zorder=2)\n",
    "    \n",
    "    ax2.set_title(f\"Trajectory ({len(vis_data_above)} events)\")\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    # 3. Rate map\n",
    "    rate_map_data = result[\"rate_map\"].T\n",
    "    im = ax3.imshow(rate_map_data, origin=\"lower\",\n",
    "                   extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]],\n",
    "                   aspect=\"equal\", cmap=\"jet\")\n",
    "    ax3.set_title(\"Rate map\")\n",
    "    ax3.axis(\"off\")\n",
    "    im.set_clim(0.0, 1.0)\n",
    "    plt.colorbar(im, cax=ax3_cbar)\n",
    "    ax3_cbar.set_ylabel(\"Norm. rate\", rotation=270, labelpad=10)\n",
    "    \n",
    "    # 4. SI histogram\n",
    "    ax4.hist(result[\"shuffled_sis\"], bins=15, color=\"gray\", alpha=0.7, \n",
    "            edgecolor=\"black\")\n",
    "    ax4.axvline(result[\"si\"], color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "    ax4.set_title(f\"SI: {result['si']:.2f}, p={result['p_val']:.3f}\")\n",
    "    ax4.set_xlabel(\"SI (bits/s)\")\n",
    "    ax4.set_ylabel(\"Count\")\n",
    "    ax4.set_box_aspect(1)\n",
    "    \n",
    "    # 5. Trace with events\n",
    "    if result[\"trace_data\"] is not None and result[\"trace_times\"] is not None:\n",
    "        trace = result[\"trace_data\"]\n",
    "        t_full = result[\"trace_times\"]\n",
    "        \n",
    "        t_max = t_full[-1] if len(t_full) > 0 else trace_time_window\n",
    "        t_start = max(0, trace_start)\n",
    "        t_end = min(t_max, t_start + trace_time_window)\n",
    "        \n",
    "        mask = (t_full >= t_start) & (t_full <= t_end)\n",
    "        t_visible = t_full[mask]\n",
    "        trace_visible = trace[mask]\n",
    "        \n",
    "        ax5.plot(t_visible, trace_visible, \"b-\", linewidth=0.5, label=\"Fluorescence\")\n",
    "        \n",
    "        # Event spikes\n",
    "        event_times_gray, event_amps_gray = [], []\n",
    "        event_times_red, event_amps_red = [], []\n",
    "        \n",
    "        if df_all_events is not None:\n",
    "            unit_all = df_all_events[df_all_events[\"unit_id\"] == unit_id]\n",
    "            if \"frame\" in unit_all.columns and \"s\" in unit_all.columns and not unit_all.empty:\n",
    "                event_t = unit_all[\"frame\"].values / neural_fps\n",
    "                event_a = unit_all[\"s\"].values\n",
    "                m = (event_t >= t_start) & (event_t <= t_end)\n",
    "                if np.any(m):\n",
    "                    event_times_gray = event_t[m]\n",
    "                    event_amps_gray = event_a[m]\n",
    "        \n",
    "        if \"frame\" in vis_data_above.columns and \"s\" in vis_data_above.columns and not vis_data_above.empty:\n",
    "            event_t = vis_data_above[\"frame\"].values / neural_fps\n",
    "            event_a = vis_data_above[\"s\"].values\n",
    "            m = (event_t >= t_start) & (event_t <= t_end)\n",
    "            if np.any(m):\n",
    "                event_times_red = event_t[m]\n",
    "                event_amps_red = event_a[m]\n",
    "        \n",
    "        # Scale spikes\n",
    "        y_min, y_max = ax5.get_ylim()\n",
    "        baseline_y = y_min\n",
    "        all_amps = np.concatenate([\n",
    "            event_amps_gray if len(event_amps_gray) > 0 else [],\n",
    "            event_amps_red if len(event_amps_red) > 0 else [],\n",
    "        ])\n",
    "        amp_max = np.max(all_amps) if len(all_amps) > 0 else 1.0\n",
    "        y_range = y_max - y_min\n",
    "        max_spike_height = y_range * 0.3\n",
    "        \n",
    "        def scale_h(a):\n",
    "            return (a / amp_max) * max_spike_height if amp_max > 0 else 0\n",
    "        \n",
    "        for t, a in zip(event_times_gray, event_amps_gray):\n",
    "            ax5.plot([t, t], [baseline_y, baseline_y + scale_h(a)], color=\"gray\", lw=1.5)\n",
    "        for t, a in zip(event_times_red, event_amps_red):\n",
    "            ax5.plot([t, t], [baseline_y, baseline_y + scale_h(a)], color=\"red\", lw=1.5)\n",
    "        \n",
    "        ax5.set_xlim(t_start, t_end)\n",
    "        ax5.set_xlabel(\"Time (s)\")\n",
    "        ax5.set_ylabel(trace_name)\n",
    "        \n",
    "        # Legend\n",
    "        legend_elements = [Line2D([0], [0], color=\"blue\", linewidth=0.5, label=\"Fluorescence\")]\n",
    "        if len(event_times_gray) > 0:\n",
    "            legend_elements.append(Line2D([0], [0], color=\"gray\", linewidth=1.5, \n",
    "                                         label=f\"Events (< {speed_threshold:.1f} px/s)\"))\n",
    "        if len(event_times_red) > 0:\n",
    "            legend_elements.append(Line2D([0], [0], color=\"red\", linewidth=1.5, \n",
    "                                         label=f\"Events (>= {speed_threshold:.1f} px/s)\"))\n",
    "        ax5.legend(handles=legend_elements, loc=\"upper left\", fontsize=8, framealpha=0.9)\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, \"No trace data\", ha=\"center\", va=\"center\", \n",
    "                transform=ax5.transAxes)\n",
    "    \n",
    "    # Status text\n",
    "    n_events = len(result[\"unit_data\"]) if not result[\"unit_data\"].empty else 0\n",
    "    p_val = result[\"p_val\"]\n",
    "    stab_corr = result[\"stability_corr\"]\n",
    "    \n",
    "    sig_pass = p_val < p_value_threshold\n",
    "    sig_text = \"pass\" if sig_pass else \"fail\"\n",
    "    sig_color = \"green\" if sig_pass else \"red\"\n",
    "    \n",
    "    if np.isnan(stab_corr):\n",
    "        stab_text, stab_color = \"N/A\", \"gray\"\n",
    "    else:\n",
    "        stab_pass = stab_corr >= stability_threshold\n",
    "        stab_text = \"pass\" if stab_pass else \"fail\"\n",
    "        stab_color = \"green\" if stab_pass else \"red\"\n",
    "    \n",
    "    txt = fig.text(0.02, 0.98, \n",
    "            f\"Unit ID: {unit_id} ({unit_idx + 1}/{n_units}) | N={n_events} events\",\n",
    "            ha=\"left\", va=\"top\", fontsize=11, fontweight=\"bold\",\n",
    "            transform=fig.transFigure)\n",
    "    text_annotations.append(txt)\n",
    "    \n",
    "    txt = fig.text(0.02, 0.95, f\"Significance (p={p_val:.3f}): \", ha=\"left\", va=\"top\",\n",
    "            fontsize=10, transform=fig.transFigure)\n",
    "    text_annotations.append(txt)\n",
    "    txt = fig.text(0.18, 0.95, sig_text, ha=\"left\", va=\"top\", fontsize=10,\n",
    "            fontweight=\"bold\", color=sig_color, transform=fig.transFigure)\n",
    "    text_annotations.append(txt)\n",
    "    \n",
    "    stab_str = f\"r={stab_corr:.2f}\" if not np.isnan(stab_corr) else \"\"\n",
    "    txt = fig.text(0.02, 0.92, f\"Stability ({stab_str}): \", ha=\"left\", va=\"top\",\n",
    "            fontsize=10, transform=fig.transFigure)\n",
    "    text_annotations.append(txt)\n",
    "    txt = fig.text(0.16, 0.92, stab_text, ha=\"left\", va=\"top\", fontsize=10,\n",
    "            fontweight=\"bold\", color=stab_color, transform=fig.transFigure)\n",
    "    text_annotations.append(txt)\n",
    "    \n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Get max trace time for slider\n",
    "max_trace_time = 0\n",
    "for r in unit_results.values():\n",
    "    if r[\"trace_times\"] is not None and len(r[\"trace_times\"]) > 0:\n",
    "        max_trace_time = max(max_trace_time, r[\"trace_times\"][-1])\n",
    "\n",
    "# Create widgets\n",
    "unit_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=n_units - 1, step=1,\n",
    "    description=\"Unit:\",\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "trace_slider = widgets.FloatSlider(\n",
    "    value=0, min=0, max=max(0, max_trace_time - trace_time_window), step=10,\n",
    "    description=\"Time (s):\",\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "# Navigation buttons\n",
    "prev_btn = widgets.Button(description=\"< Prev\", layout=widgets.Layout(width=\"80px\"))\n",
    "next_btn = widgets.Button(description=\"Next >\", layout=widgets.Layout(width=\"80px\"))\n",
    "\n",
    "def on_prev(b):\n",
    "    unit_slider.value = (unit_slider.value - 1) % n_units\n",
    "\n",
    "def on_next(b):\n",
    "    unit_slider.value = (unit_slider.value + 1) % n_units\n",
    "\n",
    "prev_btn.on_click(on_prev)\n",
    "next_btn.on_click(on_next)\n",
    "\n",
    "def update(change=None):\n",
    "    render_unit(unit_slider.value, trace_slider.value)\n",
    "\n",
    "unit_slider.observe(update, names=\"value\")\n",
    "trace_slider.observe(update, names=\"value\")\n",
    "\n",
    "# Layout\n",
    "nav_box = widgets.HBox([prev_btn, unit_slider, next_btn])\n",
    "controls = widgets.VBox([nav_box, trace_slider])\n",
    "\n",
    "# Initial render\n",
    "render_unit(0, 0)\n",
    "\n",
    "display(controls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "placecell-3.11 (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
