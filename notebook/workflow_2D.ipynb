{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Cell Analysis\n",
    "\n",
    "Interactive notebook for analyzing place cells in 2D environment navigation. Equivalent to:\n",
    "```bash\n",
    "pdm run pcell workflow visualize --config placecell/config/example_pcell_config.yaml --data user_data/WL25_20251201/WL25_20251201.yaml\n",
    "```\n",
    "\n",
    "This notebook runs the full workflow:\n",
    "1. **Deconvolution** - Extract neural events using OASIS\n",
    "2. **Event-Place Matching** - Match events to behavior positions\n",
    "3. **Interactive Visualization** - Browse place cells with scrollable interface\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This notebook uses interactive widgets (progress bars, sliders). When working over SSH, use **Jupyter Lab** instead of VSCode's notebook extension for proper widget support:\n",
    "\n",
    "```bash\n",
    "# On remote machine\n",
    "cd notebook\n",
    "jupyter lab --no-browser --port=6006\n",
    "\n",
    "# On local machine - set up SSH tunnel\n",
    "ssh -L 6006:localhost:6006 user@remote-host\n",
    "\n",
    "# Then open http://localhost:6006 in your browser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from placecell.analysis import (\n",
    "    build_event_place_dataframe,\n",
    "    compute_occupancy_map,\n",
    "    compute_unit_analysis,\n",
    "    load_curated_unit_ids,\n",
    "    load_traces,\n",
    ")\n",
    "from placecell.config import AppConfig, DataPathsConfig\n",
    "from placecell.io import load_behavior_data, load_neural_data\n",
    "from placecell.notebook import build_event_index_dataframe, create_unit_browser, run_deconvolution\n",
    "from placecell.visualization import plot_summary_scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - adjust these as needed\n",
    "CONFIG_PATH = project_root / \"placecell/config/example_pcell_config.yaml\"\n",
    "DATA_PATH = Path(\n",
    "    \"/mnt/data/minizero_analysis/202512round/202511_analysis_placecell/\"\n",
    "    \"20251201/WL25/WL25_20251201.yaml\"\n",
    ")\n",
    "DATA_DIR = DATA_PATH.parent\n",
    "OUTPUT_DIR = project_root / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load configs\n",
    "cfg = AppConfig.from_yaml(CONFIG_PATH)\n",
    "data_cfg = DataPathsConfig.from_yaml(DATA_PATH)\n",
    "\n",
    "# Apply data-specific overrides (e.g., OASIS parameters)\n",
    "cfg = cfg.with_data_overrides(data_cfg)\n",
    "\n",
    "# Resolve data paths relative to data directory\n",
    "neural_path = DATA_DIR / data_cfg.neural_path\n",
    "neural_timestamp = DATA_DIR / data_cfg.neural_timestamp\n",
    "behavior_position = DATA_DIR / data_cfg.behavior_position\n",
    "behavior_timestamp = DATA_DIR / data_cfg.behavior_timestamp\n",
    "curation_csv = (DATA_DIR / data_cfg.curation_csv) if data_cfg.curation_csv else None\n",
    "\n",
    "print(f\"Config: {CONFIG_PATH}\")\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Neural path: {neural_path}\")\n",
    "print(f\"Neural timestamp: {neural_timestamp}\")\n",
    "print(f\"Behavior position: {behavior_position}\")\n",
    "print(f\"Behavior timestamp: {behavior_timestamp}\")\n",
    "print(f\"Curation CSV: {curation_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract config values\n",
    "bodypart = cfg.behavior.bodypart\n",
    "behavior_fps = cfg.behavior.behavior_fps\n",
    "speed_threshold = cfg.behavior.speed_threshold\n",
    "speed_window_frames = cfg.behavior.speed_window_frames\n",
    "bins = cfg.behavior.spatial_map.bins\n",
    "min_occupancy = cfg.behavior.spatial_map.min_occupancy\n",
    "occupancy_sigma = cfg.behavior.spatial_map.occupancy_sigma\n",
    "activity_sigma = cfg.behavior.spatial_map.activity_sigma\n",
    "n_shuffles = cfg.behavior.spatial_map.n_shuffles\n",
    "random_seed = cfg.behavior.spatial_map.random_seed\n",
    "event_threshold_sigma = cfg.behavior.spatial_map.event_threshold_sigma\n",
    "p_value_threshold = cfg.behavior.spatial_map.p_value_threshold\n",
    "stability_threshold = cfg.behavior.spatial_map.stability_threshold\n",
    "\n",
    "# Neural config\n",
    "trace_name = cfg.neural.trace_name\n",
    "neural_fps = cfg.neural.fps\n",
    "max_units = cfg.neural.max_units\n",
    "g = cfg.neural.oasis.g\n",
    "baseline = cfg.neural.oasis.baseline\n",
    "penalty = cfg.neural.oasis.penalty\n",
    "s_min = cfg.neural.oasis.s_min\n",
    "\n",
    "# Visualization settings\n",
    "trace_time_window = 600.0  # 10 minutes window for trace display\n",
    "\n",
    "print(f\"Bodypart: {bodypart}\")\n",
    "print(f\"Speed threshold: {speed_threshold} px/s\")\n",
    "print(f\"Bins: {bins}\")\n",
    "print(f\"Shuffles: {n_shuffles}\")\n",
    "print(f\"Trace name: {trace_name}\")\n",
    "print(f\"OASIS g: {g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deconvolution\n",
    "\n",
    "Run OASIS deconvolution to extract neural events from calcium traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load traces\n",
    "print(f\"Loading traces from: {neural_path / (trace_name + '.zarr')}\")\n",
    "C_da = load_traces(neural_path, trace_name=trace_name)\n",
    "all_unit_ids = list(map(int, C_da[\"unit_id\"].values))\n",
    "print(f\"Total units in traces: {len(all_unit_ids)}\")\n",
    "\n",
    "# Filter by curation CSV if provided\n",
    "if curation_csv is not None and curation_csv.exists():\n",
    "    curated_ids = set(load_curated_unit_ids(curation_csv))\n",
    "    all_unit_ids = [uid for uid in all_unit_ids if uid in curated_ids]\n",
    "    print(f\"After curation filter: {len(all_unit_ids)} units\")\n",
    "\n",
    "# Apply max_units limit if configured\n",
    "if max_units is not None and len(all_unit_ids) > max_units:\n",
    "    all_unit_ids = all_unit_ids[:max_units]\n",
    "    print(f\"Limited to first {max_units} units\")\n",
    "\n",
    "print(f\"Will process {len(all_unit_ids)} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OASIS deconvolution\n",
    "print(f\"Running OASIS deconvolution (g={g})...\")\n",
    "\n",
    "good_unit_ids, C_list, S_list = run_deconvolution(\n",
    "    C_da=C_da,\n",
    "    unit_ids=all_unit_ids,\n",
    "    g=g,\n",
    "    baseline=baseline,\n",
    "    penalty=penalty,\n",
    "    s_min=s_min,\n",
    "    progress_bar=lambda x: tqdm(x, desc=\"Deconvolving units\"),\n",
    ")\n",
    "\n",
    "print(f\"Successfully deconvolved {len(good_unit_ids)} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build event index DataFrame\n",
    "event_index_df = build_event_index_dataframe(good_unit_ids, S_list)\n",
    "print(f\"Total events detected: {len(event_index_df)}\")\n",
    "\n",
    "# Save event index (optional)\n",
    "event_index_csv = OUTPUT_DIR / \"event_index_notebook.csv\"\n",
    "event_index_df.to_csv(event_index_csv, index=False)\n",
    "print(f\"Saved event index to: {event_index_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Event-Place Matching\n",
    "\n",
    "Match neural events to behavior positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build event-place dataframe\n",
    "print(\"Matching events to behavior positions...\")\n",
    "\n",
    "event_place_df = build_event_place_dataframe(\n",
    "    event_index_path=event_index_csv,\n",
    "    neural_timestamp_path=neural_timestamp,\n",
    "    behavior_position_path=behavior_position,\n",
    "    behavior_timestamp_path=behavior_timestamp,\n",
    "    bodypart=bodypart,\n",
    "    behavior_fps=behavior_fps,\n",
    "    speed_threshold=speed_threshold,\n",
    "    speed_window_frames=speed_window_frames,\n",
    ")\n",
    "\n",
    "print(f\"Event-place entries: {len(event_place_df)}\")\n",
    "print(f\"Unique units: {event_place_df['unit_id'].nunique()}\")\n",
    "\n",
    "# Save event-place (optional)\n",
    "event_place_csv = OUTPUT_DIR / \"event_place_notebook.csv\"\n",
    "event_place_df.to_csv(event_place_csv, index=False)\n",
    "print(f\"Saved event-place to: {event_place_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by speed threshold\n",
    "df_filtered = event_place_df[event_place_df[\"speed\"] > speed_threshold].copy()\n",
    "df_all_events = event_index_df.copy()\n",
    "\n",
    "print(f\"Speed-filtered events: {len(df_filtered)}\")\n",
    "print(f\"Unique units after filtering: {df_filtered['unit_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavior data\n",
    "trajectory_with_speed, trajectory_df = load_behavior_data(\n",
    "    behavior_position=behavior_position,\n",
    "    behavior_timestamp=behavior_timestamp,\n",
    "    bodypart=bodypart,\n",
    "    speed_window_frames=speed_window_frames,\n",
    "    speed_threshold=speed_threshold,\n",
    ")\n",
    "\n",
    "print(f\"Trajectory frames: {len(trajectory_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute occupancy map\n",
    "occupancy_time, valid_mask, x_edges, y_edges = compute_occupancy_map(\n",
    "    trajectory_df=trajectory_df,\n",
    "    bins=bins,\n",
    "    behavior_fps=behavior_fps,\n",
    "    occupancy_sigma=occupancy_sigma,\n",
    "    min_occupancy=min_occupancy,\n",
    ")\n",
    "\n",
    "print(f\"Occupancy map shape: {occupancy_time.shape}\")\n",
    "print(f\"Valid bins: {valid_mask.sum()} / {valid_mask.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neural data (for visualization)\n",
    "traces, max_proj, footprints = load_neural_data(\n",
    "    neural_path=neural_path,\n",
    "    trace_name=trace_name,\n",
    ")\n",
    "\n",
    "print(f\"Traces shape: {traces.shape if traces is not None else 'None'}\")\n",
    "print(f\"Max proj shape: {max_proj.shape if max_proj is not None else 'None'}\")\n",
    "print(f\"Footprints shape: {footprints.shape if footprints is not None else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute Unit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "if random_seed is not None:\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "# Compute analysis for each unit\n",
    "unique_units = sorted(df_filtered[\"unit_id\"].unique())\n",
    "n_units = len(unique_units)\n",
    "print(f\"Computing analysis for {n_units} units...\")\n",
    "\n",
    "unit_results = {}\n",
    "for unit_id in tqdm(unique_units, desc=\"Computing unit analysis\"):\n",
    "    result = compute_unit_analysis(\n",
    "        unit_id=unit_id,\n",
    "        df_filtered=df_filtered,\n",
    "        trajectory_df=trajectory_df,\n",
    "        occupancy_time=occupancy_time,\n",
    "        valid_mask=valid_mask,\n",
    "        x_edges=x_edges,\n",
    "        y_edges=y_edges,\n",
    "        activity_sigma=activity_sigma,\n",
    "        event_threshold_sigma=event_threshold_sigma,\n",
    "        n_shuffles=n_shuffles,\n",
    "        behavior_fps=behavior_fps,\n",
    "        min_occupancy=min_occupancy,\n",
    "        stability_threshold=stability_threshold,\n",
    "    )\n",
    "\n",
    "    # Visualization data\n",
    "    vis_data_above = result[\"events_above_threshold\"]\n",
    "    vis_data_below = pd.DataFrame()\n",
    "    if df_all_events is not None:\n",
    "        unit_all_events = df_all_events[df_all_events[\"unit_id\"] == unit_id]\n",
    "        vis_data_below = unit_all_events[unit_all_events[\"s\"] > result[\"vis_threshold\"]]\n",
    "\n",
    "    # Trace data\n",
    "    trace_data = None\n",
    "    trace_times = None\n",
    "    if traces is not None:\n",
    "        try:\n",
    "            trace_data = traces.sel(unit_id=int(unit_id)).values\n",
    "            trace_times = np.arange(len(trace_data)) / neural_fps\n",
    "        except (KeyError, IndexError):\n",
    "            pass\n",
    "\n",
    "    unit_results[unit_id] = {\n",
    "        \"rate_map\": result[\"rate_map\"],\n",
    "        \"si\": result[\"si\"],\n",
    "        \"shuffled_sis\": result[\"shuffled_sis\"],\n",
    "        \"p_val\": result[\"p_val\"],\n",
    "        \"stability_corr\": result[\"stability_corr\"],\n",
    "        \"stability_z\": result[\"stability_z\"],\n",
    "        \"vis_data_above\": vis_data_above,\n",
    "        \"vis_data_below\": vis_data_below,\n",
    "        \"unit_data\": result[\"unit_data\"],\n",
    "        \"trace_data\": trace_data,\n",
    "        \"trace_times\": trace_times,\n",
    "    }\n",
    "\n",
    "print(f\"Done. Computed analysis for {len(unit_results)} units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_occ, axes_occ = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Trajectory\n",
    "axes_occ[0].plot(trajectory_df[\"x\"], trajectory_df[\"y\"], \"k-\", alpha=0.5, linewidth=0.5)\n",
    "axes_occ[0].set_title(\"Trajectory (speed-filtered)\")\n",
    "axes_occ[0].set_aspect(\"equal\")\n",
    "axes_occ[0].axis(\"off\")\n",
    "\n",
    "# Occupancy map\n",
    "im = axes_occ[1].imshow(\n",
    "    occupancy_time.T, origin=\"lower\", cmap=\"hot\", aspect=\"equal\",\n",
    "    extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]]\n",
    ")\n",
    "axes_occ[1].contour(valid_mask.T, levels=[0.5], colors=\"white\", linewidths=1.5,\n",
    "                    extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "axes_occ[1].set_title(f\"Occupancy (sigma={occupancy_sigma}, min={min_occupancy}s)\")\n",
    "plt.colorbar(im, ax=axes_occ[1], label=\"Time (s)\")\n",
    "\n",
    "# Speed distribution\n",
    "all_speeds = trajectory_with_speed[\"speed\"].values\n",
    "speed_max = np.percentile(all_speeds[~np.isnan(all_speeds)], 99)\n",
    "axes_occ[2].hist(all_speeds.clip(max=speed_max), bins=50, color=\"gray\", alpha=0.7)\n",
    "axes_occ[2].axvline(speed_threshold, color=\"red\", linestyle=\"--\", linewidth=2,\n",
    "                    label=f\"Threshold={speed_threshold}\")\n",
    "axes_occ[2].set_title(\"Speed distribution\")\n",
    "axes_occ[2].set_xlabel(\"Speed (px/s)\")\n",
    "axes_occ[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = plot_summary_scatter(\n",
    "    unit_results,\n",
    "    p_value_threshold=p_value_threshold,\n",
    "    stability_threshold=stability_threshold,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Cell Browser\n",
    "\n",
    "Use the slider to scroll through cells. Use the time slider to scroll through the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, controls = create_unit_browser(\n",
    "    unit_results=unit_results,\n",
    "    unique_units=unique_units,\n",
    "    trajectory_df=trajectory_df,\n",
    "    df_all_events=df_all_events,\n",
    "    max_proj=max_proj,\n",
    "    footprints=footprints,\n",
    "    x_edges=x_edges,\n",
    "    y_edges=y_edges,\n",
    "    trace_name=trace_name,\n",
    "    neural_fps=neural_fps,\n",
    "    speed_threshold=speed_threshold,\n",
    "    p_value_threshold=p_value_threshold,\n",
    "    stability_threshold=stability_threshold,\n",
    "    trace_time_window=trace_time_window,\n",
    ")\n",
    "display(fig)\n",
    "display(controls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
